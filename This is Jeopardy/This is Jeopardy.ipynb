{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is Jeopardy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is slightly different than others you have encountered thus far. Instead of a step-by-step tutorial, this project contains a series of open-ended requirements which describe the project you'll be building. There are many possible ways to correctly fulfill all of these requirements, and you should expect to use the internet, Codecademy, and/or other resources when you encounter a problem that you cannot easily solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will work to write several functions that investigate a dataset of _Jeopardy!_ questions and answers. Filter the dataset for topics that you're interested in, compute the average difficulty of those questions, and train to become the next Jeopardy champion!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to complete this project, you should have completed the Pandas lessons in the <a href=\"https://www.codecademy.com/learn/paths/analyze-data-with-python\">Analyze Data with Python Skill Path</a>. You can also find those lessons in the <a href=\"https://www.codecademy.com/learn/data-processing-pandas\">Data Analysis with Pandas course</a> or the <a href=\"https://www.codecademy.com/learn/paths/data-science/\">Data Scientist Career Path</a>.\n",
    "\n",
    "Finally, the <a href=\"https://www.codecademy.com/learn/practical-data-cleaning\">Practical Data Cleaning</a> course may also be helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We've provided a csv file containing data about the game show _Jeopardy!_ in a file named `jeopardy.csv`. Load the data into a DataFrame and investigate its contents. Try to print out specific columns.\n",
    "\n",
    "   Note that in order to make this project as \"real-world\" as possible, we haven't modified the data at all - we're giving it to you exactly how we found it. As a result, this data isn't as \"clean\" as the datasets you normally find on Codecademy. More specifically, there's something odd about the column names. After you figure out the problem with the column names, you may want to rename them to make your life easier for the rest of the project.\n",
    "   \n",
    "   In order to display the full contents of a column, we've added this line of code for you:\n",
    "   \n",
    "   ```py\n",
    "   pd.set_option('display.max_colwidth', None)\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   show_number    air_date round_type                         category value  \\\n",
      "0         4680  2004-12-31  Jeopardy!                          HISTORY  $200   \n",
      "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES  $200   \n",
      "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...  $200   \n",
      "\n",
      "                                                                                                      question  \\\n",
      "0             For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory   \n",
      "1  No. 2: 1912 Olympian; football star at Carlisle Indian School; 6 MLB seasons with the Reds, Giants & Braves   \n",
      "2                     The city of Yuma in this state has a record average of 4,055 hours of sunshine each year   \n",
      "\n",
      "       answer  \n",
      "0  Copernicus  \n",
      "1  Jim Thorpe  \n",
      "2     Arizona  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "jeopardy_data = pd.read_csv('jeopardy.csv')\n",
    "jeopardy_data.columns = ['show_number', 'air_date', 'round_type', 'category', 'value', 'question', 'answer']\n",
    "print(jeopardy_data.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a function that filters the dataset for questions that contains all of the words in a list of words. For example, when the list `[\"King\", \"England\"]` was passed to our function, the function returned a DataFrame of 49 rows. Every row had the strings `\"King\"` and `\"England\"` somewhere in its `\" Question\"`.\n",
    "\n",
    "   Test your function by printing out the column containing the question of each row of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 23 entries, 14912 to 200369\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   show_number  23 non-null     int64 \n",
      " 1   air_date     23 non-null     object\n",
      " 2   round_type   23 non-null     object\n",
      " 3   category     23 non-null     object\n",
      " 4   value        23 non-null     object\n",
      " 5   question     23 non-null     object\n",
      " 6   answer       23 non-null     object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def find_word(word, string):\n",
    "    split_string = string.split()\n",
    "    return word in split_string\n",
    "\n",
    "def question_with_word(word, questions_list):\n",
    "    # return jeopardy_data.question.isin(list(word))\n",
    "    # return questions_list.apply(lambda question: word in question)\n",
    "    return questions_list.apply(lambda question: find_word(word, question))\n",
    "    \n",
    "# def question_with_word(word, words_filter):\n",
    "#     return jeopardy_data[words_filter].question.apply(lambda question: word in question)\n",
    "\n",
    "def question_filter_by_words(list_words):\n",
    "    # questions_with_words\n",
    "    words_filter = pd.Series()\n",
    "    if type(list_words) is str:\n",
    "        words_filter = question_with_word(list_words, jeopardy_data.question)\n",
    "        # with_words_filter = question_with_word(list_words, with_words_filter)\n",
    "    else:\n",
    "        for word in list_words:\n",
    "            # print(\"word: \" + word)\n",
    "            # print(\"filter lenght: {} --> filter {}\".format(len(words_filter[words_filter]), words_filter[words_filter].index))\n",
    "            ### words_filter = question_with_word(word, jeopardy_data.iloc[words_filter[words_filter].index].question)\n",
    "            if len(words_filter[words_filter]) == 0:\n",
    "                words_filter = question_with_word(word, jeopardy_data.question)\n",
    "            else:\n",
    "                words_filter = question_with_word(word, jeopardy_data[words_filter].question)\n",
    "    # return words_filter   # returns only the filter to be used in the future\n",
    "    return jeopardy_data.iloc[words_filter[words_filter].index] # returns a dataframe with the filter applied\n",
    "\n",
    "# filter1 = jeopardy_data.question.apply(lambda x: 'England' in x)\n",
    "# print(filter1[filter1].index)\n",
    "# # print(jeopardy_data[filter1].question)\n",
    "# # filter2 = jeopardy_data.question.apply(lambda jp_question: print(jp_question)) #'King' in jp_question[filter1])\n",
    "# filter2 = jeopardy_data[filter1].question.apply(lambda question: 'King' in question)\n",
    "# print(filter2[filter2].index)\n",
    "# print(jeopardy_data.iloc[filter2[filter2].index].question)\n",
    "# # print(len(jeopardy_data[filter2].question))\n",
    "\n",
    "# filter1 = question_filter_by_words(['King', 'England'])\n",
    "# print(len(filter1[filter1]))\n",
    "# print(jeopardy_data.iloc[filter1[filter1].index].question)\n",
    "king_england = question_filter_by_words(['King', 'England'])\n",
    "print(king_england.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Test your original function with a few different sets of words to try to find some ways your function breaks. Edit your function so it is more robust.\n",
    "\n",
    "   For example, think about capitalization. We probably want to find questions that contain the word `\"King\"` or `\"king\"`.\n",
    "   \n",
    "   You may also want to check to make sure you don't find rows that contain substrings of your given words. For example, our function found a question that didn't contain the word `\"king\"`, however it did contain the word `\"viking\"` &mdash; it found the `\"king\"` inside `\"viking\"`. Note that this also comes with some drawbacks &mdash; you would no longer find questions that contained words like `\"England's\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        show_number    air_date        round_type             category  value  \\\n",
      "209862         1164  1989-09-28  Double Jeopardy!  THE QUEEN'S ENGLISH   $200   \n",
      "212338         1247  1990-01-23         Jeopardy!       \"BLACK\" MOVIES   $300   \n",
      "212419         3376  1999-04-19  Double Jeopardy!    CHARLES IN CHARGE   $400   \n",
      "212807         1195  1989-11-10         Jeopardy!               QUOTES   $200   \n",
      "214050         6011  2010-11-01  Double Jeopardy!      \"NEW\" GEOGRAPHY  $1600   \n",
      "\n",
      "                                                                                                question  \\\n",
      "209862  England's monetary system no longer uses the penny; the smallest denomination is now called this   \n",
      "212338            This 1929 Hitchcock movie, his & England's 1st talkie, was shot originally as a silent   \n",
      "212419  England's Charles I dismissed it in 1629, ruled without it for 11 years, then called a short one   \n",
      "212807   England's James I called it \"Hateful to the nose, harmful to the brain, dangerous to the lungs\"   \n",
      "214050                                           This shipbuilding city is found on England's Tyne river   \n",
      "\n",
      "            answer  \n",
      "209862   New Pence  \n",
      "212338   Blackmail  \n",
      "212419  Parliament  \n",
      "212807     Tobacco  \n",
      "214050   Newcastle  \n"
     ]
    }
   ],
   "source": [
    "# filter1 = question_filter_by_words(['England\\'s'])\n",
    "# print(len(filter1[filter1]))\n",
    "# print(jeopardy_data.iloc[filter1[filter1].index].question)\n",
    "print(question_filter_by_words(['England\\'s']).tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. We may want to eventually compute aggregate statistics, like `.mean()` on the `\" Value\"` column. But right now, the values in that column are strings. Convert the`\" Value\"` column to floats. If you'd like to, you can create a new column with float values.\n",
    "\n",
    "   While most of the values in the `\" Value\"` column represent a dollar amount as a string, note that some do not &mdash; these values will need to be handled differently!\n",
    "\n",
    "   Now that you can filter the dataset of question, use your new column that contains the float values of each question to find the \"difficulty\" of certain topics. For example, what is the average value of questions that contain the word `\"King\"`?\n",
    "   \n",
    "   Make sure to use the dataset that contains the float values as the dataset you use in your filtering function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The average value of questions that contain the word(s) ['King', 'England'] is $836.36\n"
     ]
    }
   ],
   "source": [
    "def convert_str_to_float(value):\n",
    "    if ',' in value:    # discard thousands symbol\n",
    "        value = value.replace(',', '')\n",
    "    elif value == 'no value':\n",
    "        value = 'nan'\n",
    "    return float(value)\n",
    "\n",
    "\n",
    "jeopardy_data['value_float'] = jeopardy_data.value.apply(lambda value: convert_str_to_float(value) if not '$' in value else convert_str_to_float(value[1:]))\n",
    "# print(len(jeopardy_data.value_float))\n",
    "# print(jeopardy_data.value_float.mean())\n",
    "words_to_find = ['King', 'England']\n",
    "word_difficulty = question_filter_by_words(words_to_find)\n",
    "print(\"\\nThe average value of questions that contain the word(s) {} is ${:.2f}\".format(words_to_find, word_difficulty.value_float.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Write a function that returns the count of unique answers to all of the questions in a dataset. For example, after filtering the entire dataset to only questions containing the word `\"King\"`, we could then find all of the unique answers to those questions. The answer \"Henry VIII\" appeared 55 times and was the most common answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The number of questions with the word(s) \"['King', 'England']\" is 23\n",
      "The number of unique answers to all the questions with the word(s) ['King', 'England'] is 21\n"
     ]
    }
   ],
   "source": [
    "def count_unique_answers(dataframe):\n",
    "    return dataframe.answer.nunique()\n",
    "\n",
    "print(\"\\nThe number of questions with the word(s) \\\"{}\\\" is {}\".format(words_to_find, len(word_difficulty)))\n",
    "print(\"The number of unique answers to all the questions with the word(s) {} is {}\".format(words_to_find, count_unique_answers(word_difficulty)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Explore from here! This is an incredibly rich dataset, and there are so many interesting things to discover. There are a few columns that we haven't even started looking at yet. Here are some ideas on ways to continue working with this data:\n",
    "\n",
    " * Investigate the ways in which questions change over time by filtering by the date. How many questions from the 90s use the word `\"Computer\"` compared to questions from the 2000s?\n",
    " * Is there a connection between the round and the category? Are you more likely to find certain categories, like `\"Literature\"` in Single Jeopardy or Double Jeopardy?\n",
    " * Build a system to quiz yourself. Grab random questions, and use the <a href=\"https://docs.python.org/3/library/functions.html#input\">input</a> function to get a response from the user. Check to see if that response was right or wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of questions with the word(s) \"['King', 'England']\" in the period (1990, 2000) is 9\n",
      "Within a Jeopardy! the category QUOTES is 6.05% likely to appear (zoomed x100)\n",
      "Within a Double Jeopardy! the category QUOTES is 5.19% likely to appear (zoomed x100)\n",
      "Within a Final Jeopardy! the category QUOTES is 0.00% likely to appear (zoomed x100)\n",
      "Within a Tiebreaker the category QUOTES is 0.00% likely to appear (zoomed x100)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m list_round_categories \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m: round_type_rows\u001b[38;5;241m.\u001b[39mcategory\u001b[38;5;241m.\u001b[39munique()})\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# print(len(list_round_categories))\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m list_round_categories[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestions_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mlist_round_categories\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mround_type_rows\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategory\u001b[49m\u001b[43m[\u001b[49m\u001b[43mround_type_rows\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcategory\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m list_round_categories\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestions_count\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mWithin the \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{round_type}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m round with \u001b[39m\u001b[38;5;132;01m{num_categories}\u001b[39;00m\u001b[38;5;124m categories, the TOP 5 categories are:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{list_cat}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     55\u001b[0m       \u001b[38;5;241m.\u001b[39mformat(round_type\u001b[38;5;241m=\u001b[39mround_type, num_categories\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(list_round_categories), list_cat\u001b[38;5;241m=\u001b[39mlist_round_categories\u001b[38;5;241m.\u001b[39mhead()))\n",
      "File \u001b[1;32mc:\\Users\\Axado\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Axado\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Axado\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Axado\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Axado\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[90], line 52\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(category)\u001b[0m\n\u001b[0;32m     49\u001b[0m list_round_categories \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m: round_type_rows\u001b[38;5;241m.\u001b[39mcategory\u001b[38;5;241m.\u001b[39munique()})\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# print(len(list_round_categories))\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m list_round_categories[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestions_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m list_round_categories\u001b[38;5;241m.\u001b[39mcategory\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m category: round_type_rows\u001b[38;5;241m.\u001b[39mcategory[\u001b[43mround_type_rows\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategory\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcategory\u001b[49m]\u001b[38;5;241m.\u001b[39mcount())\n\u001b[0;32m     53\u001b[0m list_round_categories\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestions_count\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mWithin the \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{round_type}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m round with \u001b[39m\u001b[38;5;132;01m{num_categories}\u001b[39;00m\u001b[38;5;124m categories, the TOP 5 categories are:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{list_cat}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     55\u001b[0m       \u001b[38;5;241m.\u001b[39mformat(round_type\u001b[38;5;241m=\u001b[39mround_type, num_categories\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(list_round_categories), list_cat\u001b[38;5;241m=\u001b[39mlist_round_categories\u001b[38;5;241m.\u001b[39mhead()))\n",
      "File \u001b[1;32mc:\\Users\\Axado\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Axado\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Axado\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\Axado\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Axado\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:130\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mscalar_compare(x\u001b[38;5;241m.\u001b[39mravel(), y, op)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def count_questions_by_words_and_time_period(word, period):  # period is a year tuple (from year, to year_excluded)\n",
    "    filtered_by_word = question_filter_by_words(word)\n",
    "    years_air_date_filtered_by_word = filtered_by_word[\n",
    "        (filtered_by_word.air_date >= str(period[0])) & (filtered_by_word.air_date < str(period[1]))]\n",
    "    # years_air_date_filtered_by_word = pd.DatetimeIndex(filtered_by_word.air_date).year\n",
    "    # print(years_air_date_filtered_by_word.sort_values())\n",
    "    # years_air_date_filtered_by_word.apply(lambda date: (date >= period[0]) & (date < period[1]))\n",
    "    return len(years_air_date_filtered_by_word)\n",
    "\n",
    "# print(count_questions_by_word_and_time_period(\"King\", (1990,2000)))\n",
    "period_of_time = (1990, 2000)\n",
    "print(\"The number of questions with the word(s) \\\"{}\\\" in the period {} is {}\"\n",
    "      .format(words_to_find, period_of_time, count_questions_by_words_and_time_period(words_to_find, period_of_time)))\n",
    "\n",
    "\n",
    "def probability_category_per_round(category):\n",
    "    for round_name in round_names:\n",
    "        len_filtered_by_round_category = len(jeopardy_data[(jeopardy_data.round_type == round_name) & (jeopardy_data.category == category)])\n",
    "        # print(len_filtered_by_round_category)\n",
    "        print(\"Within a {} the category {} is {:.2f}% likely to appear (zoomed x100)\"\n",
    "            .format(round_name, category,\n",
    "                    len_filtered_by_round_category / len(jeopardy_data[jeopardy_data.round_type == round_name]) * 100 * 100\n",
    "            ))\n",
    "# print(jeopardy_data[jeopardy_data.round_type.str.contains(\"Double Jeopardy!\")])\n",
    "round_names = jeopardy_data.round_type.unique()\n",
    "category_names = jeopardy_data.category.unique()\n",
    "# print(len(category_names))\n",
    "\n",
    "print()\n",
    "# for round_type in round_names:\n",
    "probability_category_per_round(\"QUOTES\")\n",
    "\n",
    "\n",
    "#### List the TOP 5 categories by round\n",
    "## (takes a bit of time to process)\n",
    "\n",
    "# print(round_names)\n",
    "# round_type_rows = jeopardy_data[jeopardy_data.round_type == \"Tiebreaker\"]\n",
    "# print(round_type_rows)\n",
    "# list_round_categories = pd.DataFrame({'category': round_type_rows.category.unique()})\n",
    "# list_round_categories['questions_count'] = list_round_categories.category.apply(lambda category: round_type_rows.category[round_type_rows.category == category].count())\n",
    "# print(round_type_rows.category[round_type_rows.category == 'LITERARY CHARACTERS'])\n",
    "# print(list_categories)\n",
    "\n",
    "for round_type in round_names:\n",
    "# for round_type in ['Final Jeopardy!', 'Tiebreaker']:\n",
    "# round_type = 'Jeopardy!'\n",
    "# if round_type == 'Jeopardy!':\n",
    "    round_type_rows = jeopardy_data[jeopardy_data.round_type == round_type]\n",
    "    # print(len(round_type_rows))\n",
    "    list_round_categories = pd.DataFrame({'category': round_type_rows.category.unique()})\n",
    "    # print(len(list_round_categories))\n",
    "\n",
    "    list_round_categories['questions_count'] = list_round_categories.category.apply(lambda category: round_type_rows.category[round_type_rows.category == category].count())\n",
    "    list_round_categories.sort_values(by='questions_count', ascending=False, inplace=True)\n",
    "    print(\"\\nWithin the \\\"{round_type}\\\" round with {num_categories} categories, the TOP 5 categories are:\\n{list_cat}\"\n",
    "          .format(round_type=round_type, num_categories=len(list_round_categories), list_cat=list_round_categories.head()))\n",
    "    \n",
    "    del round_type_rows\n",
    "    del list_round_categories\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Compare your program to our <a href=\"https://content.codecademy.com/PRO/independent-practice-projects/jeopardy/jeopardy_solution.zip\">sample solution code</a> - remember, that your program might look different from ours (and probably will) and that's okay!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Great work! Visit <a href=\"https://discuss.codecademy.com/t/this-is-jeopardy-challenge-project-python-pandas/462365\">our forums</a> to compare your project to our sample solution code. You can also learn how to host your own solution on GitHub so you can share it with other learners! Your solution might look different from ours, and that's okay! There are multiple ways to solve these projects, and you'll learn more by seeing others' code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
